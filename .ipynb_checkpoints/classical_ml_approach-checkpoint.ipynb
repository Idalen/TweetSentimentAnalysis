{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5IvafM0o0Gr"
   },
   "source": [
    "# Classical Machine Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "P_PXSJYto2yh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>TRU</th>\n",
       "      <th>DIS</th>\n",
       "      <th>JOY</th>\n",
       "      <th>SAD</th>\n",
       "      <th>ANT</th>\n",
       "      <th>SUR</th>\n",
       "      <th>ANG</th>\n",
       "      <th>FEA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446333972562591745l</th>\n",
       "      <td>enquanto isso #lame4 rs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446341582183464960l</th>\n",
       "      <td>PETR4 subiu na bolsa 13,50. Muito bem, surpres...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448105739962548224l</th>\n",
       "      <td>vai, oibr4. um troux... ops... investidor prec...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446250331123773440l</th>\n",
       "      <td>$LREN3 - Lojas Renner (lren-nm) - Declaracao E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448130972039385089l</th>\n",
       "      <td>Barriga para dentro em uma semana - http://t.c...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456788707576532992l</th>\n",
       "      <td>$EMBR3 - Embraer (embr-nm) - Aviso Aos Acionis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458688220092715008l</th>\n",
       "      <td>ABEV3: Oportunidade de compra (+ de 20% de alt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444219554114195457l</th>\n",
       "      <td>BBAS3_Mensal !!! Alguém tem algum recado para ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451468663569141760l</th>\n",
       "      <td>Bradesco PN (BBDC4), Gráfico Semanal. Estudo t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445772239213195264l</th>\n",
       "      <td>Macktrader Investimentos : Vale PN (VALE5), Gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4183 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  TRU  \\\n",
       "tweet_id                                                                      \n",
       "446333972562591745l                            enquanto isso #lame4 rs    0   \n",
       "446341582183464960l  PETR4 subiu na bolsa 13,50. Muito bem, surpres...    1   \n",
       "448105739962548224l  vai, oibr4. um troux... ops... investidor prec...    0   \n",
       "446250331123773440l  $LREN3 - Lojas Renner (lren-nm) - Declaracao E...    0   \n",
       "448130972039385089l  Barriga para dentro em uma semana - http://t.c...   -2   \n",
       "...                                                                ...  ...   \n",
       "456788707576532992l  $EMBR3 - Embraer (embr-nm) - Aviso Aos Acionis...    0   \n",
       "458688220092715008l  ABEV3: Oportunidade de compra (+ de 20% de alt...    1   \n",
       "444219554114195457l  BBAS3_Mensal !!! Alguém tem algum recado para ...    0   \n",
       "451468663569141760l  Bradesco PN (BBDC4), Gráfico Semanal. Estudo t...    0   \n",
       "445772239213195264l  Macktrader Investimentos : Vale PN (VALE5), Gr...    0   \n",
       "\n",
       "                     DIS  JOY  SAD  ANT  SUR  ANG  FEA  \n",
       "tweet_id                                                \n",
       "446333972562591745l    0   -1   -1    0    0    0    0  \n",
       "446341582183464960l    0    1    0    0    1    0    0  \n",
       "448105739962548224l    1    0    1    0    0    1    0  \n",
       "446250331123773440l    0    0    0   -1   -1   -2   -2  \n",
       "448130972039385089l   -2   -2   -2   -2   -2    0    0  \n",
       "...                  ...  ...  ...  ...  ...  ...  ...  \n",
       "456788707576532992l    0    0    0    1    0    0    0  \n",
       "458688220092715008l    0    0    0    1    0    0    0  \n",
       "444219554114195457l    1   -2   -2   -2   -2    0    0  \n",
       "451468663569141760l    0    0    0    0    0    0    0  \n",
       "445772239213195264l    0    0    0    0    0    0    0  \n",
       "\n",
       "[4183 rows x 9 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"tweets_stock_clean.csv\").set_index('tweet_id')\n",
    "df_test = pd.read_csv(\"tweets_stocks-full_agreement.csv\").set_index('tweet_id')\n",
    "\n",
    "targets = ['TRU', 'DIS', 'JOY', 'SAD', 'ANT', 'SUR', 'ANG', 'FEA']\n",
    "\n",
    "to_delete = ['NEUTRAL', 'conf_tru_dis', 'conf_joy_sad', 'conf_ant_sur',\n",
    "       'conf_ang_fea', 'num_annot']\n",
    "\n",
    "df_train.drop(columns=to_delete, inplace=True)\n",
    "df_test.drop(columns=to_delete, inplace=True)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean tweet text by removing links, special characters\n",
    "    using simple regex statements.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(lambda text: clean_tweet(text))\n",
    "df_test['text'] = df_test['text'].apply(lambda text: clean_tweet(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    df_train[target] = df_train[target] > 0 \n",
    "    df_test[target] = df_test[target] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\", stop_words=stopwords, ngram_range=(1,2))\n",
    "\n",
    "tweets = df_train['text'].values\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "tweets = df_test['text'].values\n",
    "test_tweets = vectorizer.transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "results = df_test[targets].copy()\n",
    "\n",
    "for target in targets:\n",
    "    model.fit(freq_tweets, df_train[target])\n",
    "    results[target] = model.predict(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(results).flatten()\n",
    "y_true = np.array(df_test[targets]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9288922155688623"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15425531914893617"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48333333333333334"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2338709677419355"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOyNkhkwm4ni2DaEqXJXrpU",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "classical-ml-approach.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
